import streamlit as st
from st_paywall import add_auth
from streamlit_agraph import agraph, Node, Edge, Config
from langchain_openai import OpenAI
from langchain.prompts import PromptTemplate
import json
import re

# Definir o layout da p√°gina como centralizado
st.set_page_config(layout="wide",
                   page_title="3Knowledge üå≥üß†", page_icon="üå≥üß†")

add_auth(required=True,
         login_button_text="Login with Google",
         login_button_color="#FD504D",
         login_sidebar=False)

# Fun√ß√£o para inicializar vari√°veis de estado
def initialize_session_state():
    if 'nodes_data' not in st.session_state:
        st.session_state['nodes_data'] = None
    if 'edges_data' not in st.session_state:
        st.session_state['edges_data'] = None
    if 'response' not in st.session_state:
        st.session_state['response'] = None
    if 'response_history' not in st.session_state:
        st.session_state['response_history'] = []  # Armazenar respostas anteriores
    if 'search_query' not in st.session_state:
        st.session_state['search_query'] = None

initialize_session_state()

# Fun√ß√£o para executar o LLM
def run_ai(query):
    api_key = st.secrets["openai_api_key"]
    if not api_key:
        st.error("API key n√£o encontrada. Por favor, verifique seu arquivo secrets.toml.")
    else:
        # Configurar o LLM da OpenAI com a chave da API
        llm = OpenAI(openai_api_key=api_key,
                     temperature=0,
                     max_tokens=3000)

        # Criar um prompt template
        prompt_template = """
        Voc√™ √© um especialista em cria√ß√£o de mapas mentais, representado √°rvores de conte√∫dos principais "Nodes" e suas conexoes que representam, o objetivo e ter uma organiza√ß√£o did√°tica dos conteudos.
        1. Para cada conceito, inclua seu nome, import√¢ncia (como n√∫mero de 1 a 5) e n√≠vel hier√°rquico (level).
        2. Relacione os conceitos de forma que o mapa mental seja coeso e reflita a interdepend√™ncia dos elementos.
        3. O mapa mental deve seguir uma hierarquia l√≥gica, com os conceitos mais amplos no topo e seus subconceitos de forma hier√°rquica abaixo.
        4. A sa√≠da deve estar no formato JSON e conter duas chaves: "nodes" e "edges".
        - "nodes" deve ser uma lista de dicion√°rios contendo "id", "label", "importance" e "level".
        - "edges" deve ser uma lista de dicion√°rios contendo "source" e "target".
        5. O JSON deve estar completo, v√°lido e sem cortes ou quebras.
        6. N√£o inclua explica√ß√µes adicionais ou texto antes ou depois do JSON.
        7. O JSON criado n√£o deve ter indenta√ß√£o.
        8. Organize os conte√∫dos de forma que respeite o limite de 30 Nodes m√°ximos.

        Gere um mapa mental estruturado e detalhado para o t√≥pico "{topic}"
        """

        prompt = PromptTemplate(
            input_variables=["topic"],
            template=prompt_template,
        )

        final_prompt = prompt.format(topic=query)

        # Obter a resposta do LLM
        response = llm.invoke(final_prompt)

        # Tentar analisar a resposta como JSON
        try:
            # Extrair JSON da resposta usando express√£o regular
            match = re.search(r'\{.*\}', response, re.DOTALL)
            if match:
                json_str = match.group(0)
                data = json.loads(json_str)
                st.session_state['nodes_data'] = data["nodes"]
                st.session_state['edges_data'] = data["edges"]
                st.session_state['response'] = data

                # Armazenar a resposta no hist√≥rico
                st.session_state['response_history'].append({
                    'query': query,
                    'response': data
                })
            else:
                raise ValueError("A resposta n√£o cont√©m um JSON v√°lido.")

        except Exception as e:
            st.error(f"Erro ao analisar a resposta: {e}")
            st.text("Resposta do LLM:")
            st.text(response)

# Fun√ß√£o para exibir o gr√°fico
def display_graph():
    if st.session_state['nodes_data'] and st.session_state['edges_data']:
        # Definir cores e tamanhos dos n√≥s baseados na import√¢ncia e n√≠vel
        def get_node_size(importance):
            return 15 + importance * 5  # Tamanho baseado na import√¢ncia

        def get_node_color(level):
            # Tons de verde para o tema dark
            colors = ['#006400', '#228B22', '#32CD32', '#7CFC00', '#ADFF2F']
            return colors[level % len(colors)]  # Seleciona cor baseado no n√≠vel hier√°rquico

        node_objects = [
            Node(
                id=str(node["id"]),
                label=node["label"],
                size=get_node_size(node.get("importance", 1)),
                color=get_node_color(node.get("level", 0)),
                font={'color': 'white', 'size': 12}
            )
            for node in st.session_state['nodes_data']
        ]

        edge_objects = [
            Edge(
                source=str(edge["source"]),
                target=str(edge["target"]),
            )
            for edge in st.session_state['edges_data']
        ]

        # Configura√ß√£o para o agraph
        config = Config(
            width='100%',
            height=500,
            directed=True,
            physics=False,
            hierarchical=True,
        )

        # Exibir o gr√°fico
        return_value = agraph(nodes=node_objects, edges=edge_objects, config=config)

        # st.write(return_value)
    else:
        st.info("Por favor, insira um tema e clique em 'Mapa Mental üó∫Ô∏èüß†' para gerar o mapa mental.")

# Interface do Usu√°rio
def main():

    if not st.session_state['search_query']:
        st.header("√Årvore de Conhecimento üå≥üß†")
    else:
        st.header(f"üå≥ {st.session_state['search_query']} üß†")    

    with st.sidebar:

        st.header("Pesquisa:")
        st.session_state['search_query'] = st.text_input("Tema principal üìöüîé", "")
        search_button = st.button("Mapa Mental üó∫Ô∏èüß†")

        if search_button and st.session_state['search_query']:
            run_ai(st.session_state['search_query'])

        # Exibir o hist√≥rico de pesquisas como bot√µes
        if st.session_state['response_history']:
            st.subheader("Hist√≥rico de Pesquisas")
            for i, entry in enumerate(st.session_state['response_history']):
                query_label = entry['query']
                if st.button(query_label, key=f'history_{i}'):
                    # Quando o bot√£o √© clicado, atualiza os dados dos n√≥s e arestas
                    st.session_state['nodes_data'] = entry['response']['nodes']
                    st.session_state['edges_data'] = entry['response']['edges']
                    st.session_state['response'] = entry['response']
                    st.session_state['search_query'] = query_label

        
        st.write(f"Subscription Status: {st.session_state.user_subscribed}")
        st.write("üéâ Otimo! Voc√™ √© um usuario Premium! üéâ")
        st.write(f'Usuario: {st.session_state.email}')

    # Exibir o gr√°fico
    with st.container(border=True):
        display_graph()

if __name__ == "__main__":
    main()
